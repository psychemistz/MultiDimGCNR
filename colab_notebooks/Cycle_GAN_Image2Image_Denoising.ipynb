{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cycle_GAN_Image2Image_Denoising.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsbCd5WzF711"
      },
      "source": [
        "# Cycle_GAN_Image2Image_Style_Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmsfqKEpBDh5",
        "outputId": "268ff5f1-8b55-4eaf-df46-f87483389540"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "drive_path = '/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code'\n",
        "\n",
        "os.chdir(drive_path)\n",
        "os.getcwd() \n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "architecture\t      data\t__pycache__  Test.py\t       utils.py\n",
            "CycleGAN_Training.py  progress\tsummaries    training_weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from architecture import generator, discriminator\n",
        "# import tensorflow as tf\n",
        "import utils\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "data_path = \"data/Train\"\n",
        "n_epochs =  400#21#98#196\n",
        "batch_size = 50\n",
        "\n",
        "\n",
        "# read images\n",
        "train_img, train_labels = utils.get_img_path(data_path)\n",
        "num_train = int(len(train_img))\n",
        "print('Number of Training images: ', num_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI8y3Wt2tTLB",
        "outputId": "8547c899-682d-4229-910b-1c5fb2c2eece"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Number of Training images:  300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_vessel = train_labels\n",
        "# train_imgs, train_vessels = get_train_batch(train_img, train_labels, num_train, batch_size, Training = True)\n",
        "# input_images = image_files2arrs_normalize(train_img)\n",
        "# train_imgs, train_vessels = utils.get_train_batch(train_img, train_labels, num_train, batch_size, Training = True)"
      ],
      "metadata": {
        "id": "_V123HzWtbRz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import PIL.Image as Image  # , ImageEnhance\n",
        "# filenames = train_img\n",
        "# target_size = (256, 256)\n",
        "# # if len(img_shape) == 3:\n",
        "# #     images_arr = np.zeros((len(filenames), img_shape[0], img_shape[1], img_shape[2]), dtype=np.float32)\n",
        "# # elif len(img_shape) == 2:\n",
        "# images_arr = np.zeros((len(filenames), 256, 256, 3), dtype=np.float32)\n",
        "\n",
        "# for file_index in range(len(filenames)):\n",
        "#   # print(file_index)\n",
        "#   img = Image.open(filenames[file_index])\n",
        "#   img = img.resize(target_size, Image.ANTIALIAS)\n",
        "#   print(img)\n",
        "#   # images_arr[file_index] = np.asarray(img).astype(np.float32)/255\n",
        "    \n",
        "    \n",
        "\n",
        "#     ##################\n",
        "#     # images_arr[file_index] = np.asarray(img).astype(np.float32)\n",
        "#     # min_array = np.min(images_arr[file_index])\n",
        "#     # max_array = np.max(images_arr[file_index])\n",
        "#     # images_arr[file_index] = normalize(images_arr[file_index], min_array, max_array)\n",
        "#     # THIS IS MY LINE\n",
        "#     # images_arr[file_index]= image.extract_patches_2d(images_arr[file_index], patch_size=(256, 256), max_patches=1)\n",
        "#     # images_arr[file_index] = images_arr[file_index] - 1\n"
      ],
      "metadata": {
        "id": "MixK0mwrvZgi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images_arr.shape"
      ],
      "metadata": {
        "id": "q52cF2H_vj-g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import PIL.Image as Image  # , ImageEnhance\n",
        "# def image_files2arrs_normalize(filenames):\n",
        "#     # img_shape = image_shape(filenames[0])\n",
        "#     # images_arr = None\n",
        "#     target_size = (256, 256, 3)\n",
        "#     # if len(img_shape) == 3:\n",
        "#     #     images_arr = np.zeros((len(filenames), img_shape[0], img_shape[1], img_shape[2]), dtype=np.float32)\n",
        "#     # elif len(img_shape) == 2:\n",
        "#     images_arr = np.zeros((len(filenames), 256, 256, 3), dtype=np.float32)\n",
        "\n",
        "#     for file_index in range(len(filenames)):\n",
        "#         img = Image.open(filenames[file_index])\n",
        "#         img = img.resize(target_size, Image.ANTIALIAS)\n",
        "#         images_arr[file_index] = np.asarray(img).astype(np.float32)/255\n",
        "#         # images_arr[file_index] = np.asarray(img).astype(np.float32)\n",
        "#         # min_array = np.min(images_arr[file_index])\n",
        "#         # max_array = np.max(images_arr[file_index])\n",
        "#         # images_arr[file_index] = normalize(images_arr[file_index], min_array, max_array)\n",
        "#         # THIS IS MY LINE\n",
        "#         # images_arr[file_index]= image.extract_patches_2d(images_arr[file_index], patch_size=(256, 256), max_patches=1)\n",
        "#         # images_arr[file_index] = images_arr[file_index] - 1\n",
        "#     return images_arr"
      ],
      "metadata": {
        "id": "T-qOjRNtvKsg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_train_batch(train_img, train_labels, num_train, batch_size, Training = True):\n",
        "#     train_indices = np.random.choice(num_train, batch_size, replace=False)\n",
        "#     if (Training):\n",
        "#         train_indices2 = np.random.choice(num_train, batch_size, replace=False)\n",
        "\n",
        "#     batch_size = len(train_indices)\n",
        "#     batch_input_img_files, batch_target_img_files = [], []\n",
        "#     if (Training):\n",
        "#         for ind, idx in enumerate(train_indices):\n",
        "#             batch_input_img_files.append(train_img[idx])\n",
        "#             if (Training):\n",
        "#                 batch_target_img_files.append(train_labels[train_indices2[ind]])\n",
        "#             else:\n",
        "#                 batch_target_img_files.append(train_labels[idx])\n",
        "#     else:\n",
        "#         for ind, idx in enumerate(train_indices):\n",
        "#             batch_input_img_files.append(train_img[ind])\n",
        "#             batch_target_img_files.append(train_labels[ind])\n",
        "    \n",
        "#     # print(batch_input_img_files)\n",
        "#     # load images\n",
        "#     input_images = image_files2arrs_normalize(batch_input_img_files)\n",
        "#     target_images = image_files2arrs_normalize(batch_target_img_files)\n",
        "#     # assert (np.min(vessel) == 0 and np.max(vessel) == 1)\n",
        "\n",
        "#     all_input_images, all_target_images = [], []\n",
        "\n",
        "#     for i in range(batch_size):\n",
        "#         all_input_images.append(input_images[i])\n",
        "#         all_target_images.append(target_images[i])\n",
        "\n",
        "\n",
        "#     input_images = np.asarray(all_input_images)\n",
        "#     target_images = np.asarray(all_target_images)\n",
        "\n",
        "#     return input_images, target_images"
      ],
      "metadata": {
        "id": "HXZZ-QB0uW4v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# placeholders\n",
        "a_real = tf.placeholder(tf.float32, shape=[None, 256, 256, 3])  # unfixed-BF image (actual)\n",
        "b_real = tf.placeholder(tf.float32, shape=[None, 256, 256, 3])  # fixed-BF image (actual)\n",
        "\n",
        "phase = tf.placeholder(tf.bool, name=\"phase\")  # phase for training\n",
        "\n",
        "fake_b = generator.generator(a_real, phase_in=phase, scope='a2b')  # generate fake-fixed-BF using real-unfixed BF\n",
        "fake_a = generator.generator(b_real, phase_in=phase, scope='b2a')  # generate fake-unfixed-BF using real-fixed BF\n",
        "\n",
        "fake_b_dis = discriminator.discriminator(fake_b, training=phase, scope='b')\n",
        "fake_a_dis = discriminator.discriminator(fake_a, training=phase, scope='a')\n",
        "\n",
        "rec_a = generator.generator(fake_b, phase_in=phase, scope='b2a')  # reconstructing unfixed-BF from fake-fixed-BF\n",
        "\n",
        "rec_b = generator.generator(fake_a, phase_in=phase, scope='a2b')  # reconstructing fixed-BF from fake-unfixed-BF\n",
        "\n",
        "gen_a2b_loss = tf.reduce_mean(tf.losses.mean_squared_error(fake_b_dis, tf.ones_like(fake_b_dis)))\n",
        "gen_b2a_loss = tf.reduce_mean(tf.losses.mean_squared_error(fake_a_dis, tf.ones_like(fake_a_dis)))\n",
        "\n",
        "# cycle_loss_unfixed = tf.reduce_mean(tf.abs(a_real - rec_a))\n",
        "# cycle_loss_fixed = tf.reduce_mean(tf.abs(b_real - rec_b))\n",
        "\n",
        "cycle_loss_unfixed = tf.reduce_mean(tf.losses.mean_squared_error(a_real,rec_a))\n",
        "cycle_loss_fixed = tf.reduce_mean(tf.losses.mean_squared_error(b_real,rec_b))\n",
        "\n",
        "# final generator loss\n",
        "g_loss =  (gen_a2b_loss + gen_b2a_loss) + 10 * (cycle_loss_unfixed + cycle_loss_fixed)   # FOR deepDeconv\n",
        "# g_loss =  (gen_a2b_loss + gen_b2a_loss) + 10 * (cycle_loss_unfixed + cycle_loss_fixed)   # FOR das_despeckle\n",
        "# g_loss =  (gen_a2b_loss + gen_b2a_loss) + 20 * (cycle_loss_unfixed + cycle_loss_fixed)   # FOR deconv_despeckle\n",
        "learning_rate=0.0002\n",
        "# g_loss =  (gen_a2b_loss + gen_b2a_loss) + 20 * (cycle_loss_unfixed + cycle_loss_fixed)   # FOR deepDeconv\n",
        "# learning_rate=0.0005\n",
        "# learning_rate=0.0001\n",
        "# learning_rate=0.00001\n",
        "\n",
        "a_fake_sample = tf.placeholder(tf.float32, shape=[None, 256, 256, 3])\n",
        "b_fake_sample = tf.placeholder(tf.float32, shape=[None, 256, 256, 3])\n",
        "\n",
        "dis_a_real = discriminator.discriminator(a_real, training=phase, scope='a')\n",
        "dis_b_real = discriminator.discriminator(b_real, training=phase, scope='b')\n",
        "\n",
        "dis_a_fake_sample = discriminator.discriminator(a_fake_sample, training=phase, scope='a')\n",
        "dis_b_fake_sample = discriminator.discriminator(b_fake_sample, training=phase, scope='b')\n",
        "\n",
        "# # discriminator loss for liver\n",
        "da_loss_real = tf.reduce_mean(tf.losses.mean_squared_error(dis_a_real, tf.ones_like(dis_a_real)))\n",
        "da_loss_fake = tf.reduce_mean(tf.losses.mean_squared_error(dis_a_fake_sample, tf.zeros_like(dis_a_fake_sample)))\n",
        "da_loss = (da_loss_real + da_loss_fake) / 2\n",
        "\n",
        "db_loss_real = tf.reduce_mean(tf.losses.mean_squared_error(dis_b_real, tf.ones_like(dis_b_real)))\n",
        "db_loss_fake = tf.reduce_mean(tf.losses.mean_squared_error(dis_b_fake_sample, tf.zeros_like(dis_b_fake_sample)))\n",
        "db_loss = (db_loss_real + db_loss_fake) / 2\n",
        "\n",
        "# final discriminator loss\n",
        "d_loss = da_loss + db_loss\n",
        "\n",
        "# summaries\n",
        "gen_a2b_loss_sum = tf.summary.scalar(\"gen_a2b_loss\", gen_a2b_loss)\n",
        "gen_b2a_loss_sum = tf.summary.scalar(\"gen_b2a_loss\", gen_b2a_loss)\n",
        "\n",
        "\n",
        "cycle_loss_unfixed_sum = tf.summary.scalar(\"cycle_loss_unfixed\", cycle_loss_unfixed)\n",
        "cycle_loss_fixed_sum = tf.summary.scalar(\"cycle_loss_fixed\", cycle_loss_fixed)\n",
        "\n",
        "g_loss_sum = tf.summary.scalar(\"g_loss\", g_loss)\n",
        "g_sum = tf.summary.merge([gen_b2a_loss_sum, g_loss_sum, gen_a2b_loss_sum,\n",
        "                          cycle_loss_unfixed_sum, cycle_loss_fixed_sum])\n",
        "\n",
        "d_loss_sum = tf.summary.scalar(\"d_loss\", d_loss)\n",
        "\n",
        "db_loss_real_sum = tf.summary.scalar(\"db_loss_real\", db_loss_real)\n",
        "db_loss_fake_sum = tf.summary.scalar(\"db_loss_fake\", db_loss_fake)\n",
        "db_loss_sum = tf.summary.scalar(\"db_loss\", db_loss)\n",
        "\n",
        "da_loss_real_sum = tf.summary.scalar(\"da_loss_real\", da_loss_real)\n",
        "da_loss_fake_sum = tf.summary.scalar(\"da_loss_fake\", da_loss_fake)\n",
        "da_loss_sum = tf.summary.scalar(\"da_loss\", da_loss)\n",
        "\n",
        "d_sum = tf.summary.merge([da_loss_sum, da_loss_real_sum, da_loss_fake_sum,\n",
        "                          d_loss_sum, db_loss_sum, db_loss_real_sum, db_loss_fake_sum])\n",
        "\n",
        "# optimizer\n",
        "t_vars = tf.trainable_variables()\n",
        "d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
        "g_vars = [var for var in t_vars if 'generator' in var.name]\n",
        "for var in t_vars:\n",
        "    print(var.name)\n",
        "# d_optim = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n",
        "# g_optim = tf.train.AdamOptimizer().minimize(g_loss, var_list=g_vars)\n",
        "d_optim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(d_loss, var_list=d_vars)\n",
        "g_optim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "# initialize all valuables\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "config.gpu_options.allow_growth = True\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "resume_training = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n1YpuGvoMjw",
        "outputId": "7da88cae-1ef2-42eb-d55d-12cb1b97f859"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/generator.py:17: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  en = tf.layers.batch_normalization(en, momentum=0.9, training=training, name='bn')\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n",
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/discriminator.py:39: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  conv1 = tf.layers.batch_normalization(conv1, momentum=0.9, training=training, name='bn1')\n",
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/discriminator.py:41: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  conv1 = tf.layers.batch_normalization(conv1, momentum=0.9, training=training, name='bn2')\n",
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/discriminator.py:46: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  conv2 = tf.layers.batch_normalization(conv2, momentum=0.9, training=training, name='bn3')\n",
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/discriminator.py:48: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  conv2 = tf.layers.batch_normalization(conv2, momentum=0.9, training=training, name='bn4')\n",
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/discriminator.py:52: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  conv3 = tf.layers.batch_normalization(conv3, momentum=0.9, training=training, name='bn5')\n",
            "/content/drive/MyDrive/COLAB_DRIVE/CycleGAN_Denoising_Code/architecture/discriminator.py:54: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  conv3 = tf.layers.batch_normalization(conv3, momentum=0.9, training=training, name='bn6')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a2b_generator/en1_1/DW:0\n",
            "a2b_generator/en1_1/bias:0\n",
            "a2b_generator/en1_1/bn/gamma:0\n",
            "a2b_generator/en1_1/bn/beta:0\n",
            "a2b_generator/en1_2/DW:0\n",
            "a2b_generator/en1_2/bias:0\n",
            "a2b_generator/en1_2/bn/gamma:0\n",
            "a2b_generator/en1_2/bn/beta:0\n",
            "a2b_generator/en2_2/DW:0\n",
            "a2b_generator/en2_2/bias:0\n",
            "a2b_generator/en2_2/bn/gamma:0\n",
            "a2b_generator/en2_2/bn/beta:0\n",
            "a2b_generator/en2_3/DW:0\n",
            "a2b_generator/en2_3/bias:0\n",
            "a2b_generator/en2_3/bn/gamma:0\n",
            "a2b_generator/en2_3/bn/beta:0\n",
            "a2b_generator/en3_2/DW:0\n",
            "a2b_generator/en3_2/bias:0\n",
            "a2b_generator/en3_2/bn/gamma:0\n",
            "a2b_generator/en3_2/bn/beta:0\n",
            "a2b_generator/en3_3/DW:0\n",
            "a2b_generator/en3_3/bias:0\n",
            "a2b_generator/en3_3/bn/gamma:0\n",
            "a2b_generator/en3_3/bn/beta:0\n",
            "a2b_generator/en4_2/DW:0\n",
            "a2b_generator/en4_2/bias:0\n",
            "a2b_generator/en4_2/bn/gamma:0\n",
            "a2b_generator/en4_2/bn/beta:0\n",
            "a2b_generator/en4_3/DW:0\n",
            "a2b_generator/en4_3/bias:0\n",
            "a2b_generator/en4_3/bn/gamma:0\n",
            "a2b_generator/en4_3/bn/beta:0\n",
            "a2b_generator/en5_2/DW:0\n",
            "a2b_generator/en5_2/bias:0\n",
            "a2b_generator/en5_2/bn/gamma:0\n",
            "a2b_generator/en5_2/bn/beta:0\n",
            "a2b_generator/en5_3/DW:0\n",
            "a2b_generator/en5_3/bias:0\n",
            "a2b_generator/en5_3/bn/gamma:0\n",
            "a2b_generator/en5_3/bn/beta:0\n",
            "a2b_generator/de4_2/DW:0\n",
            "a2b_generator/de4_2/bias:0\n",
            "a2b_generator/de4_2/bn/gamma:0\n",
            "a2b_generator/de4_2/bn/beta:0\n",
            "a2b_generator/de4_3/DW:0\n",
            "a2b_generator/de4_3/bias:0\n",
            "a2b_generator/de4_3/bn/gamma:0\n",
            "a2b_generator/de4_3/bn/beta:0\n",
            "a2b_generator/de3_2/DW:0\n",
            "a2b_generator/de3_2/bias:0\n",
            "a2b_generator/de3_2/bn/gamma:0\n",
            "a2b_generator/de3_2/bn/beta:0\n",
            "a2b_generator/de3_3/DW:0\n",
            "a2b_generator/de3_3/bias:0\n",
            "a2b_generator/de3_3/bn/gamma:0\n",
            "a2b_generator/de3_3/bn/beta:0\n",
            "a2b_generator/de2_2/DW:0\n",
            "a2b_generator/de2_2/bias:0\n",
            "a2b_generator/de2_2/bn/gamma:0\n",
            "a2b_generator/de2_2/bn/beta:0\n",
            "a2b_generator/de2_3/DW:0\n",
            "a2b_generator/de2_3/bias:0\n",
            "a2b_generator/de2_3/bn/gamma:0\n",
            "a2b_generator/de2_3/bn/beta:0\n",
            "a2b_generator/de1_2/DW:0\n",
            "a2b_generator/de1_2/bias:0\n",
            "a2b_generator/de1_2/bn/gamma:0\n",
            "a2b_generator/de1_2/bn/beta:0\n",
            "a2b_generator/de1_3/DW:0\n",
            "a2b_generator/de1_3/bias:0\n",
            "a2b_generator/de1_3/bn/gamma:0\n",
            "a2b_generator/de1_3/bn/beta:0\n",
            "a2b_generator/output_layer/DW:0\n",
            "a2b_generator/output_layer/bias:0\n",
            "b2a_generator/en1_1/DW:0\n",
            "b2a_generator/en1_1/bias:0\n",
            "b2a_generator/en1_1/bn/gamma:0\n",
            "b2a_generator/en1_1/bn/beta:0\n",
            "b2a_generator/en1_2/DW:0\n",
            "b2a_generator/en1_2/bias:0\n",
            "b2a_generator/en1_2/bn/gamma:0\n",
            "b2a_generator/en1_2/bn/beta:0\n",
            "b2a_generator/en2_2/DW:0\n",
            "b2a_generator/en2_2/bias:0\n",
            "b2a_generator/en2_2/bn/gamma:0\n",
            "b2a_generator/en2_2/bn/beta:0\n",
            "b2a_generator/en2_3/DW:0\n",
            "b2a_generator/en2_3/bias:0\n",
            "b2a_generator/en2_3/bn/gamma:0\n",
            "b2a_generator/en2_3/bn/beta:0\n",
            "b2a_generator/en3_2/DW:0\n",
            "b2a_generator/en3_2/bias:0\n",
            "b2a_generator/en3_2/bn/gamma:0\n",
            "b2a_generator/en3_2/bn/beta:0\n",
            "b2a_generator/en3_3/DW:0\n",
            "b2a_generator/en3_3/bias:0\n",
            "b2a_generator/en3_3/bn/gamma:0\n",
            "b2a_generator/en3_3/bn/beta:0\n",
            "b2a_generator/en4_2/DW:0\n",
            "b2a_generator/en4_2/bias:0\n",
            "b2a_generator/en4_2/bn/gamma:0\n",
            "b2a_generator/en4_2/bn/beta:0\n",
            "b2a_generator/en4_3/DW:0\n",
            "b2a_generator/en4_3/bias:0\n",
            "b2a_generator/en4_3/bn/gamma:0\n",
            "b2a_generator/en4_3/bn/beta:0\n",
            "b2a_generator/en5_2/DW:0\n",
            "b2a_generator/en5_2/bias:0\n",
            "b2a_generator/en5_2/bn/gamma:0\n",
            "b2a_generator/en5_2/bn/beta:0\n",
            "b2a_generator/en5_3/DW:0\n",
            "b2a_generator/en5_3/bias:0\n",
            "b2a_generator/en5_3/bn/gamma:0\n",
            "b2a_generator/en5_3/bn/beta:0\n",
            "b2a_generator/de4_2/DW:0\n",
            "b2a_generator/de4_2/bias:0\n",
            "b2a_generator/de4_2/bn/gamma:0\n",
            "b2a_generator/de4_2/bn/beta:0\n",
            "b2a_generator/de4_3/DW:0\n",
            "b2a_generator/de4_3/bias:0\n",
            "b2a_generator/de4_3/bn/gamma:0\n",
            "b2a_generator/de4_3/bn/beta:0\n",
            "b2a_generator/de3_2/DW:0\n",
            "b2a_generator/de3_2/bias:0\n",
            "b2a_generator/de3_2/bn/gamma:0\n",
            "b2a_generator/de3_2/bn/beta:0\n",
            "b2a_generator/de3_3/DW:0\n",
            "b2a_generator/de3_3/bias:0\n",
            "b2a_generator/de3_3/bn/gamma:0\n",
            "b2a_generator/de3_3/bn/beta:0\n",
            "b2a_generator/de2_2/DW:0\n",
            "b2a_generator/de2_2/bias:0\n",
            "b2a_generator/de2_2/bn/gamma:0\n",
            "b2a_generator/de2_2/bn/beta:0\n",
            "b2a_generator/de2_3/DW:0\n",
            "b2a_generator/de2_3/bias:0\n",
            "b2a_generator/de2_3/bn/gamma:0\n",
            "b2a_generator/de2_3/bn/beta:0\n",
            "b2a_generator/de1_2/DW:0\n",
            "b2a_generator/de1_2/bias:0\n",
            "b2a_generator/de1_2/bn/gamma:0\n",
            "b2a_generator/de1_2/bn/beta:0\n",
            "b2a_generator/de1_3/DW:0\n",
            "b2a_generator/de1_3/bias:0\n",
            "b2a_generator/de1_3/bn/gamma:0\n",
            "b2a_generator/de1_3/bn/beta:0\n",
            "b2a_generator/output_layer/DW:0\n",
            "b2a_generator/output_layer/bias:0\n",
            "b_discriminator/conv1/DW:0\n",
            "b_discriminator/conv1/bias:0\n",
            "b_discriminator/bn1/gamma:0\n",
            "b_discriminator/bn1/beta:0\n",
            "b_discriminator/conv1_1/DW:0\n",
            "b_discriminator/conv1_1/bias:0\n",
            "b_discriminator/bn2/gamma:0\n",
            "b_discriminator/bn2/beta:0\n",
            "b_discriminator/conv2/DW:0\n",
            "b_discriminator/conv2/bias:0\n",
            "b_discriminator/bn3/gamma:0\n",
            "b_discriminator/bn3/beta:0\n",
            "b_discriminator/conv2_1/DW:0\n",
            "b_discriminator/conv2_1/bias:0\n",
            "b_discriminator/bn4/gamma:0\n",
            "b_discriminator/bn4/beta:0\n",
            "b_discriminator/conv3/DW:0\n",
            "b_discriminator/conv3/bias:0\n",
            "b_discriminator/bn5/gamma:0\n",
            "b_discriminator/bn5/beta:0\n",
            "b_discriminator/conv3_1/DW:0\n",
            "b_discriminator/conv3_1/bias:0\n",
            "b_discriminator/bn6/gamma:0\n",
            "b_discriminator/bn6/beta:0\n",
            "b_discriminator/conv4/DW:0\n",
            "b_discriminator/conv4/bias:0\n",
            "a_discriminator/conv1/DW:0\n",
            "a_discriminator/conv1/bias:0\n",
            "a_discriminator/bn1/gamma:0\n",
            "a_discriminator/bn1/beta:0\n",
            "a_discriminator/conv1_1/DW:0\n",
            "a_discriminator/conv1_1/bias:0\n",
            "a_discriminator/bn2/gamma:0\n",
            "a_discriminator/bn2/beta:0\n",
            "a_discriminator/conv2/DW:0\n",
            "a_discriminator/conv2/bias:0\n",
            "a_discriminator/bn3/gamma:0\n",
            "a_discriminator/bn3/beta:0\n",
            "a_discriminator/conv2_1/DW:0\n",
            "a_discriminator/conv2_1/bias:0\n",
            "a_discriminator/bn4/gamma:0\n",
            "a_discriminator/bn4/beta:0\n",
            "a_discriminator/conv3/DW:0\n",
            "a_discriminator/conv3/bias:0\n",
            "a_discriminator/bn5/gamma:0\n",
            "a_discriminator/bn5/beta:0\n",
            "a_discriminator/conv3_1/DW:0\n",
            "a_discriminator/conv3_1/bias:0\n",
            "a_discriminator/bn6/gamma:0\n",
            "a_discriminator/bn6/beta:0\n",
            "a_discriminator/conv4/DW:0\n",
            "a_discriminator/conv4/bias:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhuUXhO1huwD",
        "outputId": "12a8752a-bbb1-477f-aa74-9299b359e120"
      },
      "source": [
        "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
        "    sess.run(init)\n",
        "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=100)\n",
        "    sess.graph.finalize()\n",
        "    dir_save = \"./training_weights/\"\n",
        "    utils.mkdir(dir_save)\n",
        "\n",
        "    print(' [*] Loading checkpoint...')\n",
        "    checkpoint = tf.train.latest_checkpoint(dir_save)\n",
        "    indicie = int(0)\n",
        "    if resume_training is False:\n",
        "        print(' [*] Starting training')\n",
        "    elif checkpoint:\n",
        "        print(\" [*] Loading succeeds! Copy variables from % s\", checkpoint)\n",
        "        c = checkpoint.find('progress-')\n",
        "        indicie = int(checkpoint[c + 9:]) + 1\n",
        "        e_count = int(indicie / num_train)\n",
        "        print(indicie)\n",
        "        saver.restore(sess, checkpoint)\n",
        "    else:\n",
        "        print(' [*] No checkpoint. Starting training')\n",
        "        e_count = 0\n",
        "    print(\"starting indicie : \", indicie)\n",
        "    dir_ = \"./summaries/\"\n",
        "    utils.mkdir(dir_)\n",
        "    summary_writer = tf.summary.FileWriter(dir_, sess.graph)\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        ec = e_count + epoch\n",
        "        for run in range(0, num_train, batch_size):\n",
        "            a_real_ipt, b_real_ipt = utils.train_next_batch(batch_size, num_train, train_img, train_labels)\n",
        "            # run g_a2b\n",
        "            fake_b_, rec_b_ = sess.run([fake_b,rec_b], feed_dict={a_real: a_real_ipt,b_real: b_real_ipt, phase: True})\n",
        "            # run g_b2a\n",
        "            fake_a_, rec_a_ = sess.run([fake_a, rec_a], feed_dict={a_real: a_real_ipt,b_real: b_real_ipt, phase: True})\n",
        "\n",
        "            counter += 1\n",
        "            _, g_summary_str = sess.run([g_optim, g_sum],\n",
        "                                        feed_dict={a_real: a_real_ipt, b_real: b_real_ipt, phase: True})\n",
        "\n",
        "            summary_writer.add_summary(g_summary_str, global_step=indicie + counter)\n",
        "\n",
        "            _, d_summary_str = sess.run([d_optim, d_sum],\n",
        "                                        feed_dict={a_real: a_real_ipt, b_real: b_real_ipt,\n",
        "                                                   a_fake_sample: fake_a_, b_fake_sample: fake_b_, phase: True})\n",
        "\n",
        "            summary_writer.add_summary(d_summary_str, global_step=indicie + counter)\n",
        "\n",
        "            print(\"Epoch: (%2d) (%2d) [%2d / %2d]\" % (ec, indicie + counter, run, num_train))\n",
        "            # sample\n",
        "            if (indicie + counter) % 5 == 0:#508 == 0:\n",
        "                save_dir = './progress/'\n",
        "                utils.mkdir(save_dir)\n",
        "                data_in = 255 * a_real_ipt\n",
        "                img_in = data_in.astype(np.uint8)\n",
        "                data_tar = 255 * b_real_ipt\n",
        "                img_tar = data_tar.astype(np.uint8)\n",
        "                data_out = 255 * fake_b_\n",
        "                img_out = data_out.astype(np.uint8)\n",
        "                if(batch_size>1):\n",
        "                  utils.im_write(img_in[0], '%s/input.bmp' % save_dir)\n",
        "                  utils.im_write(img_tar[0], '%s/target.bmp' % save_dir)\n",
        "                  utils.im_write(img_out[0], '%s/output.bmp' % save_dir)\n",
        "                else:\n",
        "                  utils.im_write(img_in, '%s/input.bmp' % save_dir)\n",
        "                  utils.im_write(img_tar, '%s/target.bmp' % save_dir)\n",
        "                  utils.im_write(img_out, '%s/output.bmp' % save_dir)\n",
        "\n",
        "                # save\n",
        "            if (indicie + counter) % 400 == 0:\n",
        "                save_path = saver.save(sess, dir_save + \"progress\", global_step=indicie + counter)\n",
        "                print('Model saved in file: % s' % save_path)\n",
        "                print(\"Here you can include whatever code you like .....\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Loading checkpoint...\n",
            " [*] No checkpoint. Starting training\n",
            "starting indicie :  0\n"
          ]
        }
      ]
    }
  ]
}